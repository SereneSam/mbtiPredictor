{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_F3hDeH6ymG",
        "outputId": "8dcfdfdf-a7fa-4cf7-f9b6-9654fcf86da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      type                                              post1  \\\n",
            "0     INFP  'I used to play a bit of Skyrim (i found it ap...   \n",
            "1     ENFP  'Where would you live? Canada/US, somewhere wi...   \n",
            "2     INTP  'I'm an INTP who knows an ISFJ and an ESFJ. I ...   \n",
            "3     INFJ  'Some people need more, others need less. But ...   \n",
            "4     INTP  'It would be funny to Ask them,What is the dif...   \n",
            "...    ...                                                ...   \n",
            "7673  ISTP  'This happens to me! It usually happens when I...   \n",
            "7674  ENTP  'My boss was telling me he didn't know his MBT...   \n",
            "7675  ENFP  'Let me give what advice I have, based on thin...   \n",
            "7676  INFJ  'First of all, I love this thread! Thanks!  I'...   \n",
            "7677  INFJ  I adore them!!! But sometimes I can be an unhe...   \n",
            "\n",
            "                                                  post2  \\\n",
            "0     Hello,  I am a former member of PC. I decided ...   \n",
            "1     I'm passively attracted to certain attributes ...   \n",
            "2                                         cheeky nandos   \n",
            "3                                          :sun-smiley:   \n",
            "4     I think the first one might have to do with ac...   \n",
            "...                                                 ...   \n",
            "7673  How funny, I've often been criticized for bein...   \n",
            "7674  Yes. Completely. Right at the end of my Senior...   \n",
            "7675  my quotes I live by:  Death before dishonor  D...   \n",
            "7676  Also, Britain really has a comedy goldmine.  h...   \n",
            "7677  thanks everyone, your perspectives are all VER...   \n",
            "\n",
            "                                                  post3  \\\n",
            "0     sincere sensations have left my body to aid ot...   \n",
            "1     I can be both impatient and stubborn which are...   \n",
            "2                                 I love Paula Polestar   \n",
            "3     A lot of problems can be solved, if you proper...   \n",
            "4     Absolutely.I wish I could do maths and other s...   \n",
            "...                                                 ...   \n",
            "7673  Man, lunchtimes at my work can be torturous so...   \n",
            "7674  Two of the girls mentioned were peaceful frien...   \n",
            "7675  I'm glad. Your experience with a dysfunctional...   \n",
            "7676  I don't always agree with my favourite comedia...   \n",
            "7677  I've always thought I was pretty good at under...   \n",
            "\n",
            "                                                  post4  \\\n",
            "0     i've been told i look like jackson rathbone (t...   \n",
            "1     You're so cute Wait... you're not on drugs? Ca...   \n",
            "2     I'm pretty thin, but not underweight. My weigh...   \n",
            "3                                                :hugs:   \n",
            "4     I agree with Chucky.I contact people if I have...   \n",
            "...                                                 ...   \n",
            "7673  Hey bro,   The problem is not so much with oth...   \n",
            "7674  Is this because they're mistyped or overrepres...   \n",
            "7675  There definitely seems to be no real correlati...   \n",
            "7676  There might already be a thread out there abou...   \n",
            "7677  I think, as long as there is hope I am fine. W...   \n",
            "\n",
            "                                                  post5  \\\n",
            "0     this one is of me killing myself slowly with a...   \n",
            "1     I want to console and always be there for a gu...   \n",
            "2     How much wood does a woodchuck chuck if a wood...   \n",
            "3     Caffeinated and Optimistic. :smileys-sunbathin...   \n",
            "4     https://www.youtube.com/watch?v=e72tG80LmsU I ...   \n",
            "...                                                 ...   \n",
            "7673  Curse Hawking,   These are couple questions I ...   \n",
            "7674  Post to interview: Cindy Gallop, Founder & CEO...   \n",
            "7675  I ran into my dream girl when I was training f...   \n",
            "7676        https://www.youtube.com/watch?v=7zaYkdHyIuQ   \n",
            "7677  I kind of wish i knew what kind of energy I gi...   \n",
            "\n",
            "                                                  post6  \\\n",
            "0     the video is me and my band (i'm the singer cl...   \n",
            "1     Never posted in the ENFP section before since ...   \n",
            "2                                     I'm never lonely.   \n",
            "3     473746  The process is very relaxing, and the ...   \n",
            "4     https://www.youtube.com/watch?v=myc7eHGg5y4&fe...   \n",
            "...                                                 ...   \n",
            "7673  Dear fellow ISTPs.  I need your input on the q...   \n",
            "7674                                               Entj   \n",
            "7675  Breaking this into a new post:  And another th...   \n",
            "7676  Some digital surrealism by my favourite surrea...   \n",
            "7677  Wow! That is an excellent summary of INFJ-ness...   \n",
            "\n",
            "                                                  post7  \\\n",
            "0     sudden movement crackling noises camp fire  jo...   \n",
            "1     There must be something wrong with my personal...   \n",
            "2                     VIDEO - Furry Class Presentation    \n",
            "3     Sounds like my life growing up. Of course publ...   \n",
            "4     Ne.  https://www.youtube.com/watch?annotation_...   \n",
            "...                                                 ...   \n",
            "7673  I did shotokan karate.  As long as you know fe...   \n",
            "7674  I realize the INTJ/ENTP dynamic is by no means...   \n",
            "7675  500 days of summer is one of my favorite movie...   \n",
            "7676  I thought I'd share my playlist with you all. ...   \n",
            "7677  I've noticed this with a number of people arou...   \n",
            "\n",
            "                                                  post8  \\\n",
            "0     trapped in his own skin he opened his eyes to ...   \n",
            "1     Really got to start posting videos here!!     ...   \n",
            "2                     The Cringe Channel  Lord help us.   \n",
            "3                Everything is better if kept simple...   \n",
            "4     Your avatar.It looks as though the thing looks...   \n",
            "...                                                 ...   \n",
            "7673  I tend to get quite well with ENTP guys. Never...   \n",
            "7674  I realize the INTJ/ENTP dynamic is by no means...   \n",
            "7675  I'm in a long term relationship with another E...   \n",
            "7676  Hey INFJ's, you beautiful people that you are....   \n",
            "7677  thanks for the input everyone! I know I pay at...   \n",
            "\n",
            "                                                  post9  ...  \\\n",
            "0     when your cigarette smoke is inspiration enoug...  ...   \n",
            "1     Jeff Buckley! He was such a beautiful human be...  ...   \n",
            "2           https://www.youtube.com/watch?v=rkZ9sSgGPrs  ...   \n",
            "3     Fuck You. And fuck you. And fuck YOU. (Venting...  ...   \n",
            "4     Why would anyone want to fake their personalit...  ...   \n",
            "...                                                 ...  ...   \n",
            "7673  When people make all sorts of assumptions abou...  ...   \n",
            "7674  Any ENTPs out there worked for an ADD/ADHD bos...  ...   \n",
            "7675  Next/Possible Careers0   Network Administrator...  ...   \n",
            "7676  Really? I suppose a lot about my typing is con...  ...   \n",
            "7677  I don't have a very healthy relationship with ...  ...   \n",
            "\n",
            "                                                 post41  \\\n",
            "0     children redirect your eyes examine your lives...   \n",
            "1     Completely over-thinking life right now or am ...   \n",
            "2     XD im rAdomer than u!!!lol....this is a good t...   \n",
            "3     My answers are simple and to the point since I...   \n",
            "4                                                686154   \n",
            "...                                                 ...   \n",
            "7673  https://www.youtube.com/watch?v=Yb07Q4HsYb4 Tr...   \n",
            "7674  Schools. Universities, museums, academia, rese...   \n",
            "7675  awwwww, that is SO ENFP!   back at a previous ...   \n",
            "7676  I got 80%. I think it was kind of easy though,...   \n",
            "7677  :happy: thanks wonderful ENFP types! Hugs for ...   \n",
            "\n",
            "                                                 post42  \\\n",
            "0     i see it this way everything tends towards cha...   \n",
            "1     NONE OF MY LISTS ARE IN ANY ORDER  25 Songs yo...   \n",
            "2     I came from a religious family too, like many ...   \n",
            "3                               From brunette to blonde   \n",
            "4                                          686098686106   \n",
            "...                                                 ...   \n",
            "7673  Aldous Huxley wondered the same thing. This qu...   \n",
            "7674  Clever Waffle, thanks! Join the Fitocracy soun...   \n",
            "7675  Throw a shiny object in her general direction ...   \n",
            "7676  I think there is way too much negativity out t...   \n",
            "7677  I am about 90% certain a new friend of mine is...   \n",
            "\n",
            "                                                 post43  \\\n",
            "0     yes, i like going to social events to observe ...   \n",
            "1                                            ideal you    \n",
            "2                               Why are you drunk, sir?   \n",
            "3     Today like everyday, I struggle to find a bala...   \n",
            "4     It can be ASCII as well as Hexadecimal numbers...   \n",
            "...                                                 ...   \n",
            "7673  You know an ISTP is interested in you when s/h...   \n",
            "7674  ceembee, thanks!! I'll just say, sounds like w...   \n",
            "7675       I think your theory is debunked my friend XD   \n",
            "7676  ESTP's get stuff done and their whole energy i...   \n",
            "7677  Interesting - maybe this isn't a type thing th...   \n",
            "\n",
            "                                                 post44  \\\n",
            "0     lyrics that could be read off of paper like po...   \n",
            "1                                             real you    \n",
            "2     I'm so tired. Today during school I was buzzin...   \n",
            "3     Any threads out there for INFJ parents to vent...   \n",
            "4      Not yet decided on any of the existing theories.   \n",
            "...                                                 ...   \n",
            "7673  I've met plenty of SJ non-believers. I doubt r...   \n",
            "7674  My experience says, you would not. Feel free t...   \n",
            "7675  thank you for taking the time to try and help ...   \n",
            "7676  I recently read about the Se Grip and I defini...   \n",
            "7677  I really like the ENFP's I know. They are my f...   \n",
            "\n",
            "                                                 post45  \\\n",
            "0                                            ideal you    \n",
            "1                                          Introversion   \n",
            "2                         Holy shit the number of pages   \n",
            "3     Deep down we're all just wild animals that soc...   \n",
            "4     https://www.youtube.com/watch?v=J5iJSXaVvao  h...   \n",
            "...                                                 ...   \n",
            "7673  I don't think there is something wrong with be...   \n",
            "7674  Owl City!   http://www.youtube.com/watch?v=psu...   \n",
            "7675                Super stealth attack hugs!  *Hugs!*   \n",
            "7676  I don't really control my chameleonism... I'm ...   \n",
            "7677  Firstly, I really appreciate all of you who ha...   \n",
            "\n",
            "                                                 post46  \\\n",
            "0                                             real you    \n",
            "1                                                  0.43   \n",
            "2       I don't know how I would handle that situation.   \n",
            "3     I understand. As an INFJ you automatically con...   \n",
            "4     I thought  Artificial neural networks was the(...   \n",
            "...                                                 ...   \n",
            "7673  Thanks for your response, I'm really fascinate...   \n",
            "7674  In my education class we studied the layers of...   \n",
            "7675  *drives by in a rainbow colored ice cream truc...   \n",
            "7676  Yup, I have this too! My hearing is fine but I...   \n",
            "7677  an ENFP and I had a project to work on togethe...   \n",
            "\n",
            "                                                 post47  \\\n",
            "0                                          Introversion   \n",
            "1                                      73% Extroversion   \n",
            "2       I don't know how I would handle that situation.   \n",
            "3     Same here. I don't talk to either my mom or da...   \n",
            "4     I use Audacity.Which one(software) do you use ...   \n",
            "...                                                 ...   \n",
            "7673  Hi ENFPs,  Have you ever read Brave New World ...   \n",
            "7674  Thinking about it, mine would be programming o...   \n",
            "7675  Wait what? I'm not the only one who does this?...   \n",
            "7676  I'm scared of be unvalidated by them! My best ...   \n",
            "7677  I'm not saying it will be easy - seriously, so...   \n",
            "\n",
            "                                                 post48  \\\n",
            "0                                                   0.7   \n",
            "1                                                   0.7   \n",
            "2                                         Hmm....maybe.   \n",
            "3     So a non believer trolling about. A true INFJ ...   \n",
            "4     What software did you use for mixing?Btw You h...   \n",
            "...                                                 ...   \n",
            "7673  emadoe, I'm very sorry for what has happened t...   \n",
            "7674  teddy564339, collecting and stockpiling?sounds...   \n",
            "7675  I can usually be found in the library, in the ...   \n",
            "7676  Some of what you said does sound a lot like me...   \n",
            "7677  Let us know how this progresses. :) I believe ...   \n",
            "\n",
            "                                                 post49  \\\n",
            "0                                      73% Extroversion   \n",
            "1                                         40% Intuitive   \n",
            "2      Dogs are shit, cats are also shit, animals suck.   \n",
            "3     I think the easiest way to recognize it is whe...   \n",
            "4                                                683914   \n",
            "...                                                 ...   \n",
            "7673  This thread is several years old. Rising dead....   \n",
            "7674  Maura, I suppose that's fair. The way I see it...   \n",
            "7675  ENFP? Smooth? You crazy.  Maybe just because I...   \n",
            "7676  Puntje   Definitely confused. In every sense o...   \n",
            "7677  Totally have had a similar experience. I call ...   \n",
            "\n",
            "                                                 post50  \n",
            "0                                                  0.23  \n",
            "1                                                  0.73  \n",
            "2                                                376570  \n",
            "3                                                471162  \n",
            "4                                                683906  \n",
            "...                                                 ...  \n",
            "7673  Yyyeeah. I know.  At this stage of my life I a...  \n",
            "7674  Zerosum, you mean I can just go into a gym and...  \n",
            "7675  ZOMG HERCULES!  God I loved that one. I didn't...  \n",
            "7676  zosio913   This resonates a lot with me. I wou...  \n",
            "7677  Zster - your advice was particularly helpful!!...  \n",
            "\n",
            "[7678 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# rawdf = pd.read_csv(\"mbti_cleaned.csv\", dtype=str)\n",
        "rawdf = pd.read_csv(r\"C:\\Users\\seren\\OneDrive\\Documents\\datasets_3730\\mbti_cleaned.csv\")\n",
        "print(rawdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqhnVO9XV8sD",
        "outputId": "f5325247-bf8a-489d-90b0-274912304f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7678, 51)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0       INFP\n",
              "1       ENFP\n",
              "2       INTP\n",
              "3       INFJ\n",
              "4       INTP\n",
              "        ... \n",
              "7673    ISTP\n",
              "7674    ENTP\n",
              "7675    ENFP\n",
              "7676    INFJ\n",
              "7677    INFJ\n",
              "Name: type, Length: 7678, dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(rawdf.shape)\n",
        "rawdf[rawdf.columns[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grL3JPgqWn6B",
        "outputId": "e4a83d40-eb7a-4f6d-c832-6ebfc537dd1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                      0\n",
            "0     INFP |'I used to play a bit of Skyrim (i found...\n",
            "1     ENFP |'Where would you live? Canada/US, somewh...\n",
            "2     INTP |'I'm an INTP who knows an ISFJ and an ES...\n",
            "3     INFJ |'Some people need more, others need less...\n",
            "4     INTP |'It would be funny to Ask them,What is t...\n",
            "...                                                 ...\n",
            "7673  ISTP |Yyyeeah. I know.  At this stage of my li...\n",
            "7674  ENTP |Zerosum, you mean I can just go into a g...\n",
            "7675  ENFP |ZOMG HERCULES!  God I loved that one. I ...\n",
            "7676  INFJ |zosio913   This resonates a lot with me....\n",
            "7677  INFJ |Zster - your advice was particularly hel...\n",
            "\n",
            "[383900 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "indexed = pd.DataFrame()\n",
        "for i in range(1, rawdf.shape[1]):\n",
        "  #col = pd.concat((rawdf[rawdf.columns[0]], rawdf.rename(mapper={i:'post1'}, axis = 1)[rawdf.columns[i]]), axis = 1)\n",
        "  col = rawdf[rawdf.columns[0]] + \" |\" + rawdf[rawdf.columns[i]]\n",
        "  #print(col)\n",
        "  indexed = pd.concat((indexed, col), axis=0)\n",
        "print(indexed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DujbbYRSfj1g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "df = pd.DataFrame(np.row_stack([indexed.columns, indexed.values]), columns = [\"type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_KLpVLXep0W",
        "outputId": "3a71a20c-37f1-4de8-f51e-896bfe7a61eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         type                                               post\n",
            "0         NaN                                                NaN\n",
            "1       INFP   'I used to play a bit of Skyrim (i found it ap...\n",
            "2       ENFP   'Where would you live? Canada/US, somewhere wi...\n",
            "3       INTP   'I'm an INTP who knows an ISFJ and an ESFJ. I ...\n",
            "4       INFJ   'Some people need more, others need less. But ...\n",
            "...       ...                                                ...\n",
            "383896  ISTP   Yyyeeah. I know.  At this stage of my life I a...\n",
            "383897  ENTP   Zerosum, you mean I can just go into a gym and...\n",
            "383898  ENFP   ZOMG HERCULES!  God I loved that one. I didn't...\n",
            "383899  INFJ   zosio913   This resonates a lot with me. I wou...\n",
            "383900  INFJ   Zster - your advice was particularly helpful!!...\n",
            "\n",
            "[383901 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df[[\"type\", \"post\"]] = df[\"type\"].str.split('|', expand=True)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0oa8NJ9gOKy",
        "outputId": "1418827a-682a-4562-f631-a8dbb8c3b2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         type                                               post\n",
            "1       INFP   'I used to play a bit of Skyrim (i found it ap...\n",
            "2       ENFP   'Where would you live? Canada/US, somewhere wi...\n",
            "3       INTP   'I'm an INTP who knows an ISFJ and an ESFJ. I ...\n",
            "4       INFJ   'Some people need more, others need less. But ...\n",
            "5       INTP   'It would be funny to Ask them,What is the dif...\n",
            "...       ...                                                ...\n",
            "383896  ISTP   Yyyeeah. I know.  At this stage of my life I a...\n",
            "383897  ENTP   Zerosum, you mean I can just go into a gym and...\n",
            "383898  ENFP   ZOMG HERCULES!  God I loved that one. I didn't...\n",
            "383899  INFJ   zosio913   This resonates a lot with me. I wou...\n",
            "383900  INFJ   Zster - your advice was particularly helpful!!...\n",
            "\n",
            "[383900 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df.drop(axis=0, index=0)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOEWzOiNgmJ1"
      },
      "source": [
        "**WOOOOOOOOO LETS FUCKING GO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPaYsFsvEVc6",
        "outputId": "35593660-d72c-4ad8-d451-73474d548107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.1)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: filelock in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\seren\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vqrpTdWqEeLN"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7I01UjBElJB",
        "outputId": "a8f9894a-e120-463b-93ac-af57bda27d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         type                                               post\n",
            "1       INFP   'I used to play a bit of Skyrim (i found it ap...\n",
            "2       ENFP   'Where would you live? Canada/US, somewhere wi...\n",
            "3       INTP   'I'm an INTP who knows an ISFJ and an ESFJ. I ...\n",
            "4       INFJ   'Some people need more, others need less. But ...\n",
            "5       INTP   'It would be funny to Ask them,What is the dif...\n",
            "...       ...                                                ...\n",
            "345506  ISTP   I don't think there is something wrong with be...\n",
            "345507  ENTP   Owl City!   http://www.youtube.com/watch?v=psu...\n",
            "345508  ENFP                 Super stealth attack hugs!  *Hugs!*\n",
            "345509  INFJ   I don't really control my chameleonism... I'm ...\n",
            "345510  INFJ   Firstly, I really appreciate all of you who ha...\n",
            "\n",
            "[345510 rows x 2 columns]\n",
            "         type                                               post\n",
            "364706  INTP   I wonder if being an INTP makes you more prone...\n",
            "364707  ENFJ   woo! men waiting for a wife seem to be very ra...\n",
            "364708  ISFJ   what's to understand? he's a cheat, get away a...\n",
            "364709  INTP   it's 2014, people with no college education re...\n",
            "364710  INTP   There are three good things about Christmas: 1...\n",
            "...       ...                                                ...\n",
            "383896  ISTP   Yyyeeah. I know.  At this stage of my life I a...\n",
            "383897  ENTP   Zerosum, you mean I can just go into a gym and...\n",
            "383898  ENFP   ZOMG HERCULES!  God I loved that one. I didn't...\n",
            "383899  INFJ   zosio913   This resonates a lot with me. I wou...\n",
            "383900  INFJ   Zster - your advice was particularly helpful!!...\n",
            "\n",
            "[19195 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "trainset = df[:math.floor(df.shape[0]*0.90)]\n",
        "valset = df[math.floor(df.shape[0]*0.90):math.floor(df.shape[0]*0.95)]\n",
        "testset = df[math.floor(df.shape[0]*0.95):]\n",
        "trainset = trainset.astype(str)\n",
        "valset = valset.astype(str)\n",
        "testset = testset.astype(str)\n",
        "print(trainset)\n",
        "print(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-oP_y8lhFx2H"
      },
      "outputs": [],
      "source": [
        "trtup = list(trainset.itertuples(index=False, name=None))\n",
        "vatup = list(valset.itertuples(index=False, name=None))\n",
        "tetup = list(testset.itertuples(index=False, name=None))\n",
        "#print(trtup)\n",
        "#print(tetup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gclh63DXF8rO"
      },
      "outputs": [],
      "source": [
        "train_iter = iter(trtup)\n",
        "val_iter = iter(vatup)\n",
        "test_iter = iter(tetup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6J9t6ItxNXyQ"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "tok = get_tokenizer(\"basic_english\")\n",
        "def yield_tokens(dataIter):\n",
        "    for _, text in dataIter:\n",
        "        yield tok(text)\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nA1-nyDTSSLS"
      },
      "outputs": [],
      "source": [
        "label_map = {'INTJ ': 0, 'INTP ': 1, 'ENTJ ': 2, 'ENTP ': 3,\n",
        "             'INFJ ': 4, 'INFP ': 5, 'ENFJ ': 6, 'ENFP ': 7,\n",
        "             'ISTJ ': 8, 'ISFJ ': 9, 'ESTJ ': 10,'ESFJ ': 11,\n",
        "             'ISTP ': 12,'ISFP ': 13,'ESTP ': 14,'ESFP ': 15,\n",
        "             'nan' : 16}\n",
        "text_pipe = lambda x: vocab(tok(x))\n",
        "label_pipe = lambda x: label_map[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLLinQKZS1Be",
        "outputId": "e5cf6e42-df44-4791-acf5-69855a5cd6ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_pipe('ENTP ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sqFMSN8FUUh7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KqJlrp2Qb_Ql"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "  labelList, textList, offsets = [], [], [0]\n",
        "  for _label, _text in batch:\n",
        "      labelList.append(label_pipe(_label))\n",
        "      processed_text = torch.tensor(text_pipe(_text), dtype=torch.int64)\n",
        "      textList.append(processed_text)\n",
        "      offsets.append(processed_text.size(0))\n",
        "  labelList = torch.tensor(labelList, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  textList = torch.cat(textList)\n",
        "  return labelList.to(device), textList.to(device), offsets.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r8fJkrCLkOyh"
      },
      "outputs": [],
      "source": [
        "dlTrain = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "dlVal = DataLoader(val_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "dlTest = DataLoader(test_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PapM9k6elDn8"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "  def __init__(self, voc_size, embedding, num_classes):\n",
        "    super(TextClassifier, self).__init__()\n",
        "    self.embedding = nn.EmbeddingBag(voc_size, embedding, sparse=False)\n",
        "    self.fc = nn.Linear(embedding, num_classes)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "      initrange = 0.5\n",
        "      self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "      self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "      self.fc.bias.data.zero_()\n",
        "  def forward(self, text, offsets):\n",
        "      embedded = self.embedding(text, offsets)\n",
        "      return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1R_epeM8mZav"
      },
      "outputs": [],
      "source": [
        "numClasses = 17\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassifier(vocab_size, emsize, numClasses).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sYlF1_LRmrr1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(dl):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0,0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, offsets) in enumerate(dl):\n",
        "      optimizer.zero_grad()\n",
        "      predLabel = model(text, offsets)\n",
        "      loss = criterion(predLabel, label)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n",
        "      optimizer.step()\n",
        "      total_acc += (predLabel.argmax(1) == label).sum().item()\n",
        "      total_count  += label.size(0)\n",
        "      if idx % log_interval == 0 and idx > 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\"Epoch {:3d}: {:5d}/{:5d} batches: accuracy {:8.3f}\".format(epoch, idx, len(dl), total_acc/total_count))\n",
        "        total_acc, total_count = 0, 0\n",
        "        start_time = time.time()\n",
        "def evaluate(dl):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dl):\n",
        "      predLabel = model(text, offsets)\n",
        "      loss = criterion(predLabel, label)\n",
        "      total_acc += (predLabel.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc / total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Nq1fqW2eo_MH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "EPOCHS = 25\n",
        "LR = 5\n",
        "BATCH = 128\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.01)\n",
        "total_accu = None\n",
        "\n",
        "train_iter = iter(trtup)\n",
        "val_iter = iter(vatup)\n",
        "test_iter = iter(tetup)\n",
        "\n",
        "train_ds = to_map_style_dataset(train_iter)\n",
        "val_ds = to_map_style_dataset(val_iter)\n",
        "test_ds = to_map_style_dataset(test_iter)\n",
        "\n",
        "dlTrain = DataLoader(train_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)\n",
        "dlVal = DataLoader(val_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)\n",
        "dlTest = DataLoader(test_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMXM3zSvr0s9",
        "outputId": "35d46398-4de9-4e97-eafc-8f733e8d2d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['INFP ' 'ENFP ' 'INTP ' 'INFJ ' 'ENTP ' 'INTJ ' 'ENTJ ' 'ISTJ ' 'ISFJ '\n",
            " 'ENFJ ' 'ESTP ' 'ESFP ' 'ISTP ' 'ISFP ' 'ESTJ ' 'ESFJ ' nan]\n",
            "1         INFP \n",
            "2         ENFP \n",
            "3         INTP \n",
            "4         INFJ \n",
            "5         INTP \n",
            "          ...  \n",
            "383896    ISTP \n",
            "383897    ENTP \n",
            "383898    ENFP \n",
            "383899    INFJ \n",
            "383900    INFJ \n",
            "Name: type, Length: 383900, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.type.unique())\n",
        "with pd.option_context('display.max_seq_items', None):\n",
        "    print (df.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EOFiOdfztnP",
        "outputId": "f7b3e2df-015d-4fd7-dfc2-f363176807a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\seren\\AppData\\Local\\Temp\\ipykernel_10696\\2943983012.py:14: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   1:   500/ 2700 batches: accuracy    0.204\n",
            "Epoch   1:  1000/ 2700 batches: accuracy    0.215\n",
            "Epoch   1:  1500/ 2700 batches: accuracy    0.216\n",
            "Epoch   1:  2000/ 2700 batches: accuracy    0.219\n",
            "Epoch   1:  2500/ 2700 batches: accuracy    0.222\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   1: Time: 98.03, Valid Accuracy:    0.209\n",
            "-----------------------------------------------------------\n",
            "Epoch   2:   500/ 2700 batches: accuracy    0.231\n",
            "Epoch   2:  1000/ 2700 batches: accuracy    0.234\n",
            "Epoch   2:  1500/ 2700 batches: accuracy    0.234\n",
            "Epoch   2:  2000/ 2700 batches: accuracy    0.235\n",
            "Epoch   2:  2500/ 2700 batches: accuracy    0.238\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   2: Time: 91.61, Valid Accuracy:    0.239\n",
            "-----------------------------------------------------------\n",
            "Epoch   3:   500/ 2700 batches: accuracy    0.242\n",
            "Epoch   3:  1000/ 2700 batches: accuracy    0.244\n",
            "Epoch   3:  1500/ 2700 batches: accuracy    0.245\n",
            "Epoch   3:  2000/ 2700 batches: accuracy    0.245\n",
            "Epoch   3:  2500/ 2700 batches: accuracy    0.249\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   3: Time: 90.79, Valid Accuracy:    0.248\n",
            "-----------------------------------------------------------\n",
            "Epoch   4:   500/ 2700 batches: accuracy    0.254\n",
            "Epoch   4:  1000/ 2700 batches: accuracy    0.251\n",
            "Epoch   4:  1500/ 2700 batches: accuracy    0.252\n",
            "Epoch   4:  2000/ 2700 batches: accuracy    0.253\n",
            "Epoch   4:  2500/ 2700 batches: accuracy    0.252\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   4: Time: 97.90, Valid Accuracy:    0.246\n",
            "-----------------------------------------------------------\n",
            "Epoch   5:   500/ 2700 batches: accuracy    0.268\n",
            "Epoch   5:  1000/ 2700 batches: accuracy    0.269\n",
            "Epoch   5:  1500/ 2700 batches: accuracy    0.268\n",
            "Epoch   5:  2000/ 2700 batches: accuracy    0.267\n",
            "Epoch   5:  2500/ 2700 batches: accuracy    0.270\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   5: Time: 85.59, Valid Accuracy:    0.254\n",
            "-----------------------------------------------------------\n",
            "Epoch   6:   500/ 2700 batches: accuracy    0.269\n",
            "Epoch   6:  1000/ 2700 batches: accuracy    0.270\n",
            "Epoch   6:  1500/ 2700 batches: accuracy    0.270\n",
            "Epoch   6:  2000/ 2700 batches: accuracy    0.267\n",
            "Epoch   6:  2500/ 2700 batches: accuracy    0.270\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   6: Time: 82.68, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch   7:   500/ 2700 batches: accuracy    0.270\n",
            "Epoch   7:  1000/ 2700 batches: accuracy    0.271\n",
            "Epoch   7:  1500/ 2700 batches: accuracy    0.268\n",
            "Epoch   7:  2000/ 2700 batches: accuracy    0.268\n",
            "Epoch   7:  2500/ 2700 batches: accuracy    0.268\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   7: Time: 85.88, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch   8:   500/ 2700 batches: accuracy    0.267\n",
            "Epoch   8:  1000/ 2700 batches: accuracy    0.270\n",
            "Epoch   8:  1500/ 2700 batches: accuracy    0.268\n",
            "Epoch   8:  2000/ 2700 batches: accuracy    0.270\n",
            "Epoch   8:  2500/ 2700 batches: accuracy    0.268\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   8: Time: 84.60, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch   9:   500/ 2700 batches: accuracy    0.267\n",
            "Epoch   9:  1000/ 2700 batches: accuracy    0.268\n",
            "Epoch   9:  1500/ 2700 batches: accuracy    0.272\n",
            "Epoch   9:  2000/ 2700 batches: accuracy    0.269\n",
            "Epoch   9:  2500/ 2700 batches: accuracy    0.269\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   9: Time: 80.86, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  10:   500/ 2700 batches: accuracy    0.269\n",
            "Epoch  10:  1000/ 2700 batches: accuracy    0.269\n",
            "Epoch  10:  1500/ 2700 batches: accuracy    0.267\n",
            "Epoch  10:  2000/ 2700 batches: accuracy    0.271\n",
            "Epoch  10:  2500/ 2700 batches: accuracy    0.268\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  10: Time: 80.15, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  11:   500/ 2700 batches: accuracy    0.272\n",
            "Epoch  11:  1000/ 2700 batches: accuracy    0.269\n",
            "Epoch  11:  1500/ 2700 batches: accuracy    0.267\n",
            "Epoch  11:  2000/ 2700 batches: accuracy    0.268\n",
            "Epoch  11:  2500/ 2700 batches: accuracy    0.269\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  11: Time: 83.55, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  12:   500/ 2700 batches: accuracy    0.266\n",
            "Epoch  12:  1000/ 2700 batches: accuracy    0.268\n",
            "Epoch  12:  1500/ 2700 batches: accuracy    0.269\n",
            "Epoch  12:  2000/ 2700 batches: accuracy    0.267\n",
            "Epoch  12:  2500/ 2700 batches: accuracy    0.273\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  12: Time: 80.13, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  13:   500/ 2700 batches: accuracy    0.270\n",
            "Epoch  13:  1000/ 2700 batches: accuracy    0.270\n",
            "Epoch  13:  1500/ 2700 batches: accuracy    0.268\n",
            "Epoch  13:  2000/ 2700 batches: accuracy    0.272\n",
            "Epoch  13:  2500/ 2700 batches: accuracy    0.265\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  13: Time: 96.90, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  14:   500/ 2700 batches: accuracy    0.268\n",
            "Epoch  14:  1000/ 2700 batches: accuracy    0.271\n",
            "Epoch  14:  1500/ 2700 batches: accuracy    0.268\n",
            "Epoch  14:  2000/ 2700 batches: accuracy    0.267\n",
            "Epoch  14:  2500/ 2700 batches: accuracy    0.268\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  14: Time: 103.85, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  15:   500/ 2700 batches: accuracy    0.270\n",
            "Epoch  15:  1000/ 2700 batches: accuracy    0.270\n",
            "Epoch  15:  1500/ 2700 batches: accuracy    0.265\n",
            "Epoch  15:  2000/ 2700 batches: accuracy    0.271\n",
            "Epoch  15:  2500/ 2700 batches: accuracy    0.270\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  15: Time: 103.06, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  16:   500/ 2700 batches: accuracy    0.270\n",
            "Epoch  16:  1000/ 2700 batches: accuracy    0.268\n",
            "Epoch  16:  1500/ 2700 batches: accuracy    0.266\n",
            "Epoch  16:  2000/ 2700 batches: accuracy    0.271\n",
            "Epoch  16:  2500/ 2700 batches: accuracy    0.268\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  16: Time: 103.31, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  17:   500/ 2700 batches: accuracy    0.268\n",
            "Epoch  17:  1000/ 2700 batches: accuracy    0.268\n",
            "Epoch  17:  1500/ 2700 batches: accuracy    0.270\n",
            "Epoch  17:  2000/ 2700 batches: accuracy    0.268\n",
            "Epoch  17:  2500/ 2700 batches: accuracy    0.271\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  17: Time: 107.71, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  18:   500/ 2700 batches: accuracy    0.268\n",
            "Epoch  18:  1000/ 2700 batches: accuracy    0.267\n",
            "Epoch  18:  1500/ 2700 batches: accuracy    0.270\n",
            "Epoch  18:  2000/ 2700 batches: accuracy    0.271\n",
            "Epoch  18:  2500/ 2700 batches: accuracy    0.267\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  18: Time: 112.86, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  19:   500/ 2700 batches: accuracy    0.267\n",
            "Epoch  19:  1000/ 2700 batches: accuracy    0.269\n",
            "Epoch  19:  1500/ 2700 batches: accuracy    0.269\n",
            "Epoch  19:  2000/ 2700 batches: accuracy    0.269\n",
            "Epoch  19:  2500/ 2700 batches: accuracy    0.269\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  19: Time: 112.65, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  20:   500/ 2700 batches: accuracy    0.269\n",
            "Epoch  20:  1000/ 2700 batches: accuracy    0.271\n",
            "Epoch  20:  1500/ 2700 batches: accuracy    0.270\n",
            "Epoch  20:  2000/ 2700 batches: accuracy    0.269\n",
            "Epoch  20:  2500/ 2700 batches: accuracy    0.267\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  20: Time: 114.05, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  21:   500/ 2700 batches: accuracy    0.268\n",
            "Epoch  21:  1000/ 2700 batches: accuracy    0.272\n",
            "Epoch  21:  1500/ 2700 batches: accuracy    0.267\n",
            "Epoch  21:  2000/ 2700 batches: accuracy    0.270\n",
            "Epoch  21:  2500/ 2700 batches: accuracy    0.266\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  21: Time: 152.24, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  22:   500/ 2700 batches: accuracy    0.266\n",
            "Epoch  22:  1000/ 2700 batches: accuracy    0.269\n",
            "Epoch  22:  1500/ 2700 batches: accuracy    0.269\n",
            "Epoch  22:  2000/ 2700 batches: accuracy    0.268\n",
            "Epoch  22:  2500/ 2700 batches: accuracy    0.272\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  22: Time: 149.63, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  23:   500/ 2700 batches: accuracy    0.267\n",
            "Epoch  23:  1000/ 2700 batches: accuracy    0.267\n",
            "Epoch  23:  1500/ 2700 batches: accuracy    0.270\n",
            "Epoch  23:  2000/ 2700 batches: accuracy    0.271\n",
            "Epoch  23:  2500/ 2700 batches: accuracy    0.269\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  23: Time: 154.06, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  24:   500/ 2700 batches: accuracy    0.269\n",
            "Epoch  24:  1000/ 2700 batches: accuracy    0.268\n",
            "Epoch  24:  1500/ 2700 batches: accuracy    0.269\n",
            "Epoch  24:  2000/ 2700 batches: accuracy    0.267\n",
            "Epoch  24:  2500/ 2700 batches: accuracy    0.270\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  24: Time: 110.91, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n",
            "Epoch  25:   500/ 2700 batches: accuracy    0.270\n",
            "Epoch  25:  1000/ 2700 batches: accuracy    0.266\n",
            "Epoch  25:  1500/ 2700 batches: accuracy    0.269\n",
            "Epoch  25:  2000/ 2700 batches: accuracy    0.269\n",
            "Epoch  25:  2500/ 2700 batches: accuracy    0.270\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  25: Time: 111.63, Valid Accuracy:    0.253\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "  epoch_start = time.time()\n",
        "  train(dlTrain)\n",
        "  accu_val = evaluate(dlVal)\n",
        "  if total_accu is not None and total_accu > accu_val:\n",
        "    scheduler.step()\n",
        "  else:\n",
        "    total_accu = accu_val\n",
        "  print('-'*59)\n",
        "  print(\"End of Epoch {:3d}: Time: {:5.2f}, Valid Accuracy: {:8.3f}\".format(epoch, time.time() - epoch_start, accu_val))\n",
        "  print('-'*59)\n",
        "  torch.save(model, 'SAVETHISTOYOURLOCAL.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnC__MwvhaC_",
        "outputId": "3102117a-d153-42ee-ecdb-bd73d58f03a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.25428497004428235\n"
          ]
        }
      ],
      "source": [
        "print(evaluate(dlTest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WyLmXgBFwKKb"
      },
      "outputs": [],
      "source": [
        "def predict(text, pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlNY3_g6x8N9"
      },
      "source": [
        "Using my own tweets as testing data:\n",
        "  INFJ: 1\n",
        "  INTP: 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oOYVBDKqvQL9",
        "outputId": "89ad3636-2300-41d7-94ab-34cd3eb31dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "post: \n",
            "To all of those who have asked, I will not be going to the Inauguration on January 20th.\n",
            "The 75,000,000 great American Patriots who voted for me, AMERICA FIRST, and MAKE AMERICA GREAT AGAIN, will have a GIANT VOICE long into the future. They will not be disrespected or treated unfairly in any way, shape or form!!!\n",
            "I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law & Order  respect the Law and our great men and women in Blue. Thank you!\n",
            "Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!\n",
            "These scoundrels are only toying with the \n",
            "@sendavidperdue\n",
            " (a great guy) vote. Just didnt want to announce quite yet. Theyve got as many ballots as are necessary. Rigged Election!\n",
            "Even Mexico uses Voter I.D.\n",
            "\n",
            "Type: ENFJ \n"
          ]
        }
      ],
      "source": [
        "s = '''\n",
        "To all of those who have asked, I will not be going to the Inauguration on January 20th.\n",
        "The 75,000,000 great American Patriots who voted for me, AMERICA FIRST, and MAKE AMERICA GREAT AGAIN, will have a GIANT VOICE long into the future. They will not be disrespected or treated unfairly in any way, shape or form!!!\n",
        "I am asking for everyone at the U.S. Capitol to remain peaceful. No violence! Remember, WE are the Party of Law & Order  respect the Law and our great men and women in Blue. Thank you!\n",
        "Please support our Capitol Police and Law Enforcement. They are truly on the side of our Country. Stay peaceful!\n",
        "These scoundrels are only toying with the \n",
        "@sendavidperdue\n",
        " (a great guy) vote. Just didnt want to announce quite yet. Theyve got as many ballots as are necessary. Rigged Election!\n",
        "Even Mexico uses Voter I.D.\n",
        "'''\n",
        "\n",
        "label_map = {'INTJ ': 0, 'INTP ': 1, 'ENTJ ': 2, 'ENTP ': 3,\n",
        "             'INFJ ': 4, 'INFP ': 5, 'ENFJ ': 6, 'ENFP ': 7,\n",
        "             'ISTJ ': 8, 'ISFJ ': 9, 'ESTJ ': 10,'ESFJ ': 11,\n",
        "             'ISTP ': 12,'ISFP ': 13,'ESTP ': 14,'ESFP ': 15,\n",
        "             'nan' : 16}\n",
        "mbti_map = {v: k for k, v in label_map.items()}\n",
        "model = model.to('cpu')\n",
        "print(\"post: %s\\nType: %s\" % (s, mbti_map[predict(s, text_pipe)]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
