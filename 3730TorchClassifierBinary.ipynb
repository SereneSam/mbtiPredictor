{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas\n",
        "%pip install numpy\n",
        "%pip install torch"
      ],
      "metadata": {
        "id": "cppDRGYfN4Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset"
      ],
      "metadata": {
        "id": "gRcrq4BkNlni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_F3hDeH6ymG",
        "outputId": "e868dcd8-5758-4e4a-a49d-5a200fe30df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     type                                              post1  \\\n",
            "0       F  'Yes peace is the absence of conflict - your I...   \n",
            "1       F  'Yes, I have gone completely cold hearted towa...   \n",
            "2       F  'Why not both? It's more fun to be open to dif...   \n",
            "3       F  Yeah, you're not gonna win her over with logic...   \n",
            "4       F                                          'Explain?   \n",
            "...   ...                                                ...   \n",
            "7673    T  'Whats up guys.   The other night I was thinki...   \n",
            "7674    T  'I've been told I have a death glare.  My wife...   \n",
            "7675    T  'No, I wouldn't say I?m stubborn at all. I can...   \n",
            "7676    T  'I suppose I have one thing to add. Eights are...   \n",
            "7677    T  'This happens to me! It usually happens when I...   \n",
            "\n",
            "                                                  post2  \\\n",
            "0     I'm just going to reallybriefly respond:  1. Y...   \n",
            "1     I'm a heavy introvert, yet everyone at work lo...   \n",
            "2     I imagine INFPs as dreamy space prince, dyed h...   \n",
            "3                                       Wassup Fatum =P   \n",
            "4                                  Aurelion Sol is ESTJ   \n",
            "...                                                 ...   \n",
            "7673  Im saying, this sounds more like a 20 somethin...   \n",
            "7674  This.  You are an ISTP, right?  Most of us are...   \n",
            "7675  Mm, yeah. What you have explained is the class...   \n",
            "7676  I reckon I'd count. I'm doing my Bachelor's in...   \n",
            "7677  How funny, I've often been criticized for bein...   \n",
            "\n",
            "                                                  post3  \\\n",
            "0     Yeah, I can't say I like Nietzsche either.  I ...   \n",
            "1         Filled it out =) Good luck on your project!!!   \n",
            "2     They're cute!  A bit awkward, but sensible and...   \n",
            "3     I haven't seen it man, but I don't really like...   \n",
            "4     It's categorization based on personality. Grow...   \n",
            "...                                                 ...   \n",
            "7673  I dont think this is an ISTP thing dude, its j...   \n",
            "7674  Oh yeah, that's me.  Gotta check you out from ...   \n",
            "7675  I have found they are much more crazy! When I ...   \n",
            "7676   All round chill person.  Probably likes monkeys.   \n",
            "7677  Man, lunchtimes at my work can be torturous so...   \n",
            "\n",
            "                                                  post4  \\\n",
            "0     Yes, it's true that the person who gives more ...   \n",
            "1     I would think INFJ would be the most thinking ...   \n",
            "2                                           hey guys ;)   \n",
            "3     so um.... I've hit an all time low! After bein...   \n",
            "4     Well I don't know why your ego would side with...   \n",
            "...                                                 ...   \n",
            "7673  I'm in Canada and I'm of the understanding the...   \n",
            "7674  I think ISTPs would fare well for that 12 hour...   \n",
            "7675                                meh...young people.   \n",
            "7676  You seem really jolly with a healthy sense of ...   \n",
            "7677  Hey bro,   The problem is not so much with oth...   \n",
            "\n",
            "                                                  post5  \\\n",
            "0     First, I *totally* relate to every feeling you...   \n",
            "1     Very good question =)!!  I do this a lot, Ill ...   \n",
            "2     I often get asked to BE quiet but yeah...........   \n",
            "3     Horton the Elephant from Dr. Seuss' Horton Hea...   \n",
            "4     ISFJ: Past oriented/focused, nostalgic, often ...   \n",
            "...                                                 ...   \n",
            "7673                             Video games...all day.   \n",
            "7674  The Raylan Givens quote from Justified applies...   \n",
            "7675  30 minutes from NYC, 10 minutes from Newark NJ...   \n",
            "7676  Happy go lucky and likes kittens to a degree t...   \n",
            "7677  Curse Hawking,   These are couple questions I ...   \n",
            "\n",
            "                                                  post6  \\\n",
            "0     I don't know what ENFJ/ESTP relationships look...   \n",
            "1                           I was thinking isfp as well   \n",
            "2     I really like boy names that start with A, so ...   \n",
            "3     A hungry African lion came across two men.  On...   \n",
            "4             Said the Baby Boomer to the Gen Z :stomp:   \n",
            "...                                                 ...   \n",
            "7673  Ignoring usually works fine for me. My advice,...   \n",
            "7674  Tell him that.  Verbatim.  Well, I'd leave out...   \n",
            "7675  My husband in an ESTJ and this is him to the l...   \n",
            "7676  Likes Japanese art and is a general art fan.  ...   \n",
            "7677  Dear fellow ISTPs.  I need your input on the q...   \n",
            "\n",
            "                                                  post7  \\\n",
            "0     The only chance he had to conclude was to make...   \n",
            "1     Words of affirmation followed closely by quali...   \n",
            "2     Depends in what, if it's something insignifica...   \n",
            "3                                         I got a 66 =D   \n",
            "4     Oh please stop being so hostile about the corr...   \n",
            "...                                                 ...   \n",
            "7673  I have a story and then a point. So stick with...   \n",
            "7674  I think I can do empathy.  I struggle with sym...   \n",
            "7675  Oh cool! I was starting to feel like an old ha...   \n",
            "7676  Anything I can share with your mom during our ...   \n",
            "7677  I did shotokan karate.  As long as you know fe...   \n",
            "\n",
            "                                                  post8  \\\n",
            "0     Mmm. I will give a very quick response, maybe ...   \n",
            "1     Being a F dom type doesn't mean we can't Think...   \n",
            "2     I wasn't good in school at all lol I would alw...   \n",
            "3     also, Adasta you still haven't said what you'r...   \n",
            "4     Actually, K-pop is the best thing that has hap...   \n",
            "...                                                 ...   \n",
            "7673          But first...let me take a selfie!  126665   \n",
            "7674  People that try to be funny.  You either have ...   \n",
            "7675  @zynthaxx and @Erbse, thanks your advice! I ha...   \n",
            "7676  I like SP/Sx or Sx/Sp.   Social instinct isn't...   \n",
            "7677  I tend to get quite well with ENTP guys. Never...   \n",
            "\n",
            "                                                  post9  ...  \\\n",
            "0     ENFJ  TMLT quit pretty much every job after a ...  ...   \n",
            "1     My favorite feeling in the entire world is whe...  ...   \n",
            "2     I want a dognut but I'm already fat so I can't...  ...   \n",
            "3     2 things:  1) You are... RIDICULOUSLY wrong in...  ...   \n",
            "4     Well, based on what you've written here, I see...  ...   \n",
            "...                                                 ...  ...   \n",
            "7673                                             onions  ...   \n",
            "7674  I do.  I gots my beverages and chips (that I b...  ...   \n",
            "7675                                      Just curious.  ...   \n",
            "7676  I'm doing Industrial Physics in college and wh...  ...   \n",
            "7677  When people make all sorts of assumptions abou...  ...   \n",
            "\n",
            "                                                 post41  \\\n",
            "0     (ENFP doesn't realize it's not actually a stag...   \n",
            "1     From what I'm seeing you come across as an INF...   \n",
            "2                    What happens if you boil a banana?   \n",
            "3     The thing that always gets me about Lord Of Th...   \n",
            "4     Fe vs Fi test   1.Are you more about people an...   \n",
            "...                                                 ...   \n",
            "7673                         That's why I said, update.   \n",
            "7674  I don't think I have any just sitting around d...   \n",
            "7675  How old are you? That says a lot when it comes...   \n",
            "7676  myst91 social instinct is last in my stacking ...   \n",
            "7677  https://www.youtube.com/watch?v=Yb07Q4HsYb4 Tr...   \n",
            "\n",
            "                                                 post42  \\\n",
            "0     ENFPs couldn't even afford the cheap seats: al...   \n",
            "1     I just graduated high school(2013) and I'v nev...   \n",
            "2     How to become fiends with ENFP?  Get in their ...   \n",
            "3     Well, right now I just work in a shop, but tom...   \n",
            "4     I thought of Chad as a very stupid Ne dom with...   \n",
            "...                                                 ...   \n",
            "7673  Can we get a mobile update with this? I'm kind...   \n",
            "7674  My weakness is that I don't wash my hands afte...   \n",
            "7675  huh?  Why is sentance [sic] misspelled? Is thi...   \n",
            "7676  4. DAT scarf and top are unique if nothing els...   \n",
            "7677  Aldous Huxley wondered the same thing. This qu...   \n",
            "\n",
            "                                                 post43  \\\n",
            "0     Typical ENFP: can't even make a come-back with...   \n",
            "1     Nope thats not strange I took karate classes a...   \n",
            "2     I was a white knight. Introverted though. From...   \n",
            "3                                                 50015   \n",
            "4     You took a bite from the apple, Adam But I was...   \n",
            "...                                                 ...   \n",
            "7673  I usually just go blow some peoples heads off ...   \n",
            "7674  I have a good friend that I'm confident is a E...   \n",
            "7675  Giving kids an ass to kiss is never in a paren...   \n",
            "7676  I'm newish to MBTI, and only recently was type...   \n",
            "7677  You know an ISTP is interested in you when s/h...   \n",
            "\n",
            "                                                 post44  \\\n",
            "0     ENFJs non-dominant hand is usually helping an ...   \n",
            "1     Id give it a 5, the beginning I could relate t...   \n",
            "2     That INFJs are unsocial creatures that never c...   \n",
            "3     not to seem stupid but um... whats a pompadour...   \n",
            "4     I pretty much play whatever my friends play. R...   \n",
            "...                                                 ...   \n",
            "7673  Oh yeah. I used to get badgered by my aunt all...   \n",
            "7674  I've learned over the years that people are di...   \n",
            "7675  nope I'm not either. I haven't talked to my mo...   \n",
            "7676  Thank you. But yeah it's more like I don't rea...   \n",
            "7677  I've met plenty of SJ non-believers. I doubt r...   \n",
            "\n",
            "                                                 post45  \\\n",
            "0                      The ENFPs right hand got married   \n",
            "1     The descriptions at best are stereotypes of a ...   \n",
            "2     I'm feeling like shit because i just ate frenc...   \n",
            "3                                             50013  =p   \n",
            "4     Hello Venus:  Alice: ENFP Lime: ENTP Nara: ISF...   \n",
            "...                                                 ...   \n",
            "7673  I don't cry very often, but when I do it's lik...   \n",
            "7674  Only because I don't care how the step scale w...   \n",
            "7675  Wow, how is it that no one saw these traits in...   \n",
            "7676  Ireland is a small country, and yes the town I...   \n",
            "7677  I don't think there is something wrong with be...   \n",
            "\n",
            "                                                 post46  \\\n",
            "0     This forum has gotten farther and farther from...   \n",
            "1     Every since playing Morrowind back in the day ...   \n",
            "2     *Morning light shining through the window crea...   \n",
            "3     Um... some disturbingly beautiful works of art...   \n",
            "4     Fiestar:  Cao Lu: ENFJ Jei: ESFP Yezi: ISTJ Hy...   \n",
            "...                                                 ...   \n",
            "7673  I haven't seen Hunger Games, but this type vs....   \n",
            "7674  What did you score on a MBTI test (or one of t...   \n",
            "7675  My thing is if you've violated most laws your ...   \n",
            "7676  I get a lot of this. But I looked at your enne...   \n",
            "7677  Thanks for your response, I'm really fascinate...   \n",
            "\n",
            "                                                 post47  \\\n",
            "0     Ah. ENFPs giving unsolicited gifts to the worl...   \n",
            "1     Something Iv been told my group of friends tha...   \n",
            "2      I don't read books. Books are for intellectuals.   \n",
            "3                              ....INFP's SWEAR?!?! O.O   \n",
            "4     I kind of regret making my username my real na...   \n",
            "...                                                 ...   \n",
            "7673                      Finally, someone who gets it.   \n",
            "7674  OK.  Whatever, dude.  You're cool.  (same thin...   \n",
            "7675  For years I've been wanting to finish my degre...   \n",
            "7676  I actually looked up the same personality type...   \n",
            "7677  Hi ENFPs,  Have you ever read Brave New World ...   \n",
            "\n",
            "                                                 post48  \\\n",
            "0     hiding spots = mom's basement  & ESFP already ...   \n",
            "1                                You sound like an INFP   \n",
            "2     I want to be the ceregate mother for Milo Yian...   \n",
            "3     I find myself pouting as I type things and rea...   \n",
            "4     Assuming they're corresponding...  Easy-going ...   \n",
            "...                                                 ...   \n",
            "7673  I love customizing stuff. For example, paintba...   \n",
            "7674  I just read the entire thread and I'm still st...   \n",
            "7675  I really think I'd do alright. I say husband w...   \n",
            "7676  19, but 20 in January. End of an era. End of a...   \n",
            "7677  emadoe, I'm very sorry for what has happened t...   \n",
            "\n",
            "                                                 post49  \\\n",
            "0                     ESFPs tend not to notice anything   \n",
            "1                            Thanks for sharing :happy:   \n",
            "2     Normal hug: Stranger hugs INFJ: INFJ stiffens ...   \n",
            "3     Ramona Flowers... although there would be a lo...   \n",
            "4     Those all sound awesome (I've tried chamomile ...   \n",
            "...                                                 ...   \n",
            "7673                 Yeah, I tend to make everyone cry.   \n",
            "7674  I don't like to commit myself about heaven and...   \n",
            "7675  YYAASSS! That's what I'm tawkin' about Galldun...   \n",
            "7676  A few questions for the rest of you since I wa...   \n",
            "7677  This thread is several years old. Rising dead....   \n",
            "\n",
            "                                                 post50  \n",
            "0     (INFJ: analyzes situation in head for three ho...  \n",
            "1     *** I do not share this thinking I providing n...  \n",
            "2                      *goes in with magical INFJ hug*'  \n",
            "3     *lies down in provocative pose*  TAKE ME NOW, ...  \n",
            "4     *screams into the void* NOTHING  Just kidding....  \n",
            "...                                                 ...  \n",
            "7673  You do realize the entire basis of MBTI is der...  \n",
            "7674  You had me at too much work involved.  ISTPs u...  \n",
            "7675  You know this actually worked?  The thing that...  \n",
            "7676  You randomly disassemble an old mobile phone a...  \n",
            "7677  Yyyeeah. I know.  At this stage of my life I a...  \n",
            "\n",
            "[7678 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "# reads a binary classification raw data file stored as a CSV of format\n",
        "#   type    post1   post2   post3   ...   post50\n",
        "#   <mbti>  <post>  <post>  <post>  ...   <post>\n",
        "#   ...     ...     ...     ...     ...   ...\n",
        "rawdf = pd.read_csv(\"mbti_cleaned_TF.csv\", dtype=str)\n",
        "print(rawdf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rawdf.shape)\n",
        "rawdf[rawdf.columns[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqhnVO9XV8sD",
        "outputId": "ca88506f-e436-43af-abec-ba8ba7fe56c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7678, 51)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       F\n",
              "1       F\n",
              "2       F\n",
              "3       F\n",
              "4       F\n",
              "       ..\n",
              "7673    T\n",
              "7674    T\n",
              "7675    T\n",
              "7676    T\n",
              "7677    T\n",
              "Name: type, Length: 7678, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert this dataframe to a single, long column containing every single type and post in pairs of <type>|<post>\n",
        "indexed = pd.DataFrame()\n",
        "for i in range(1, rawdf.shape[1]):\n",
        "  #col = pd.concat((rawdf[rawdf.columns[0]], rawdf.rename(mapper={i:'post1'}, axis = 1)[rawdf.columns[i]]), axis = 1)\n",
        "  col = rawdf[rawdf.columns[0]] + \"|\" + rawdf[rawdf.columns[i]]\n",
        "  #print(col)\n",
        "  indexed = pd.concat((indexed, col), axis=0)\n",
        "print(indexed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grL3JPgqWn6B",
        "outputId": "80e6033b-29dd-4ebe-ee04-a58396b56bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                      0\n",
            "0     F|'Yes peace is the absence of conflict - your...\n",
            "1     F|'Yes, I have gone completely cold hearted to...\n",
            "2     F|'Why not both? It's more fun to be open to d...\n",
            "3     F|Yeah, you're not gonna win her over with log...\n",
            "4                                           F|'Explain?\n",
            "...                                                 ...\n",
            "7673  T|You do realize the entire basis of MBTI is d...\n",
            "7674  T|You had me at too much work involved.  ISTPs...\n",
            "7675  T|You know this actually worked?  The thing th...\n",
            "7676  T|You randomly disassemble an old mobile phone...\n",
            "7677  T|Yyyeeah. I know.  At this stage of my life I...\n",
            "\n",
            "[383900 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New Dataframe splits the old one to reach our final format, N pairs of posts and corresponding types\n",
        "df = pd.DataFrame(np.row_stack([indexed.columns, indexed.values]), columns = [\"type\"])\n",
        "df[[\"type\", \"post\"]] = df[\"type\"].str.split('|', expand=True)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_KLpVLXep0W",
        "outputId": "48e48f41-bdf5-4480-b6f3-9fc2f787bb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       type                                               post\n",
            "0       NaN                                                NaN\n",
            "1         F  'Yes peace is the absence of conflict - your I...\n",
            "2         F  'Yes, I have gone completely cold hearted towa...\n",
            "3         F  'Why not both? It's more fun to be open to dif...\n",
            "4         F  Yeah, you're not gonna win her over with logic...\n",
            "...     ...                                                ...\n",
            "383896    T  You do realize the entire basis of MBTI is der...\n",
            "383897    T  You had me at too much work involved.  ISTPs u...\n",
            "383898    T  You know this actually worked?  The thing that...\n",
            "383899    T  You randomly disassemble an old mobile phone a...\n",
            "383900    T  Yyyeeah. I know.  At this stage of my life I a...\n",
            "\n",
            "[383901 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop null values left from the splitting process\n",
        "df = df.drop(axis=0, index=0)\n",
        "df = df.dropna()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0oa8NJ9gOKy",
        "outputId": "63bb7ba9-14df-4932-cf4b-055bc6456bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       type                                               post\n",
            "1         F  'Yes peace is the absence of conflict - your I...\n",
            "2         F  'Yes, I have gone completely cold hearted towa...\n",
            "3         F  'Why not both? It's more fun to be open to dif...\n",
            "4         F  Yeah, you're not gonna win her over with logic...\n",
            "5         F                                          'Explain?\n",
            "...     ...                                                ...\n",
            "383896    T  You do realize the entire basis of MBTI is der...\n",
            "383897    T  You had me at too much work involved.  ISTPs u...\n",
            "383898    T  You know this actually worked?  The thing that...\n",
            "383899    T  You randomly disassemble an old mobile phone a...\n",
            "383900    T  Yyyeeah. I know.  At this stage of my life I a...\n",
            "\n",
            "[383898 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide data into training, val, and testing\n",
        "# Datasets are turned into iters for later use in dataloaders\n",
        "trainset = df[:math.floor(df.shape[0]*0.80)]\n",
        "valset = df[math.floor(df.shape[0]*0.80):math.floor(df.shape[0]*0.85)]\n",
        "testset = df[math.floor(df.shape[0]*0.85):]\n",
        "trainset = trainset.astype(str)\n",
        "valset = valset.astype(str)\n",
        "testset = testset.astype(str)\n",
        "trtup = list(trainset.itertuples(index=False, name=None))\n",
        "vatup = list(valset.itertuples(index=False, name=None))\n",
        "tetup = list(testset.itertuples(index=False, name=None))\n",
        "train_iter = iter(trtup)\n",
        "val_iter = iter(vatup)\n",
        "test_iter = iter(tetup)"
      ],
      "metadata": {
        "id": "-oP_y8lhFx2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocabulary off of training data iterator\n",
        "# (this means any word in testing that wasn't in training will be tokenized as <unk>)\n",
        "tok = get_tokenizer(\"basic_english\")\n",
        "def yield_tokens(dataIter):\n",
        "    for _, text in dataIter:\n",
        "        yield tok(text)\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "6J9t6ItxNXyQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d70deda4-ff2e-4676-bf57-f142a25681e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c20046ceecf5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataIter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data pipeline lambda functions for converting labels and post-words into their token forms\n",
        "label_map = {'T': 0, 'F': 1}\n",
        "text_pipe = lambda x: vocab(tok(x))\n",
        "label_pipe = lambda x: label_map[x]"
      ],
      "metadata": {
        "id": "nA1-nyDTSSLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "sqFMSN8FUUh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batching function for dataloaders\n",
        "def collate_batch(batch):\n",
        "  labelList, textList, offsets = [], [], [0]\n",
        "  for _label, _text in batch:\n",
        "      labelList.append(label_pipe(_label))\n",
        "      processed_text = torch.tensor(text_pipe(_text), dtype=torch.int64)\n",
        "      textList.append(processed_text)\n",
        "      offsets.append(processed_text.size(0))\n",
        "  labelList = torch.tensor(labelList, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  textList = torch.cat(textList)\n",
        "  return labelList.to(device), textList.to(device), offsets.to(device)"
      ],
      "metadata": {
        "id": "KqJlrp2Qb_Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate dataloaders\n",
        "dlTrain = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "dlVal = DataLoader(val_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "dlTest = DataLoader(test_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "r8fJkrCLkOyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture Class\n",
        "# 1 embedding bag followed by 2 dense layers\n",
        "class TextClassifier(nn.Module):\n",
        "  def __init__(self, voc_size, embedding, num_classes):\n",
        "    super(TextClassifier, self).__init__()\n",
        "    self.embedding = nn.EmbeddingBag(voc_size, 2*embedding, sparse=False)\n",
        "    self.fc1 = nn.Linear(2*embedding, embedding)\n",
        "    self.fc2 = nn.Linear(embedding, num_classes)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "      initrange = 0.5\n",
        "      self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "      self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "      self.fc1.bias.data.zero_()\n",
        "      self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "      self.fc2.bias.data.zero_()\n",
        "  def forward(self, text, offsets):\n",
        "      embedded = self.embedding(text, offsets)\n",
        "      filled = self.fc1(embedded)\n",
        "      return self.fc2(filled)"
      ],
      "metadata": {
        "id": "PapM9k6elDn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters and instantiation\n",
        "numClasses = 2\n",
        "vocab_size = len(vocab)\n",
        "emsize = 32\n",
        "model = TextClassifier(vocab_size, emsize, numClasses).to(device)"
      ],
      "metadata": {
        "id": "1R_epeM8mZav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and evaluation functions\n",
        "# (NOTE: these use global models and accumulators, just because schedulers are weird otherwise)\n",
        "def train(dl):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0,0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, offsets) in enumerate(dl):\n",
        "      optimizer.zero_grad()\n",
        "      predLabel = model(text, offsets)\n",
        "      loss = criterion(predLabel, label)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n",
        "      optimizer.step()\n",
        "      total_acc += (predLabel.argmax(1) == label).sum().item()\n",
        "      total_count  += label.size(0)\n",
        "      if idx % log_interval == 0 and idx > 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\"Epoch {:3d}: {:5d}/{:5d} batches: accuracy {:8.3f}\".format(epoch, idx, len(dl), total_acc/total_count))\n",
        "        total_acc, total_count = 0, 0\n",
        "        start_time = time.time()\n",
        "def evaluate(dl):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dl):\n",
        "      predLabel = model(text, offsets)\n",
        "      loss = criterion(predLabel, label)\n",
        "      total_acc += (predLabel.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc / total_count"
      ],
      "metadata": {
        "id": "sYlF1_LRmrr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete model hyperparams and instantiate new batch loaders\n",
        "EPOCHS = 10\n",
        "LR = 5\n",
        "BATCH = 128\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.01)\n",
        "total_accu = None\n",
        "\n",
        "train_iter = iter(trtup)\n",
        "val_iter = iter(vatup)\n",
        "test_iter = iter(tetup)\n",
        "\n",
        "train_ds = to_map_style_dataset(train_iter)\n",
        "val_ds = to_map_style_dataset(val_iter)\n",
        "test_ds = to_map_style_dataset(test_iter)\n",
        "\n",
        "dlTrain = DataLoader(train_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)\n",
        "dlVal = DataLoader(val_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)\n",
        "dlTest = DataLoader(test_ds, batch_size = BATCH, shuffle=True, collate_fn = collate_batch)"
      ],
      "metadata": {
        "id": "Nq1fqW2eo_MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.type.unique())\n",
        "with pd.option_context('display.max_seq_items', None):\n",
        "    print (df.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMXM3zSvr0s9",
        "outputId": "a4c6462a-f3ac-4a47-f114-05d4bd77e994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['F' 'T']\n",
            "1         F\n",
            "2         F\n",
            "3         F\n",
            "4         F\n",
            "5         F\n",
            "         ..\n",
            "383896    T\n",
            "383897    T\n",
            "383898    T\n",
            "383899    T\n",
            "383900    T\n",
            "Name: type, Length: 383898, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  epoch_start = time.time()\n",
        "  train(dlTrain)\n",
        "  accu_val = evaluate(dlVal)\n",
        "  if total_accu is not None and total_accu > accu_val:\n",
        "    scheduler.step()\n",
        "  else:\n",
        "    total_accu = accu_val\n",
        "  print('-'*59)\n",
        "  print(\"End of Epoch {:3d}: Time: {:5.2f}, Valid Accuracy: {:8.3f}\".format(epoch, time.time() - epoch_start, accu_val))\n",
        "  print('-'*59)\n",
        "torch.save(model, \"SAVETHISjudgeperceive\")"
      ],
      "metadata": {
        "id": "3EOFiOdfztnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f447693-cd39-4f1f-b47c-cc3d4a1430c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-be1b1dc80fa3>:14: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1:   500/ 2700 batches: accuracy    0.575\n",
            "Epoch   1:  1000/ 2700 batches: accuracy    0.579\n",
            "Epoch   1:  1500/ 2700 batches: accuracy    0.580\n",
            "Epoch   1:  2000/ 2700 batches: accuracy    0.581\n",
            "Epoch   1:  2500/ 2700 batches: accuracy    0.583\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   1: Time: 23.57, Valid Accuracy:    0.591\n",
            "-----------------------------------------------------------\n",
            "Epoch   2:   500/ 2700 batches: accuracy    0.585\n",
            "Epoch   2:  1000/ 2700 batches: accuracy    0.578\n",
            "Epoch   2:  1500/ 2700 batches: accuracy    0.586\n",
            "Epoch   2:  2000/ 2700 batches: accuracy    0.585\n",
            "Epoch   2:  2500/ 2700 batches: accuracy    0.589\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   2: Time: 22.58, Valid Accuracy:    0.593\n",
            "-----------------------------------------------------------\n",
            "Epoch   3:   500/ 2700 batches: accuracy    0.585\n",
            "Epoch   3:  1000/ 2700 batches: accuracy    0.589\n",
            "Epoch   3:  1500/ 2700 batches: accuracy    0.586\n",
            "Epoch   3:  2000/ 2700 batches: accuracy    0.587\n",
            "Epoch   3:  2500/ 2700 batches: accuracy    0.587\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   3: Time: 23.18, Valid Accuracy:    0.594\n",
            "-----------------------------------------------------------\n",
            "Epoch   4:   500/ 2700 batches: accuracy    0.592\n",
            "Epoch   4:  1000/ 2700 batches: accuracy    0.594\n",
            "Epoch   4:  1500/ 2700 batches: accuracy    0.583\n",
            "Epoch   4:  2000/ 2700 batches: accuracy    0.585\n",
            "Epoch   4:  2500/ 2700 batches: accuracy    0.595\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   4: Time: 23.05, Valid Accuracy:    0.593\n",
            "-----------------------------------------------------------\n",
            "Epoch   5:   500/ 2700 batches: accuracy    0.609\n",
            "Epoch   5:  1000/ 2700 batches: accuracy    0.613\n",
            "Epoch   5:  1500/ 2700 batches: accuracy    0.615\n",
            "Epoch   5:  2000/ 2700 batches: accuracy    0.615\n",
            "Epoch   5:  2500/ 2700 batches: accuracy    0.613\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   5: Time: 22.64, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n",
            "Epoch   6:   500/ 2700 batches: accuracy    0.614\n",
            "Epoch   6:  1000/ 2700 batches: accuracy    0.613\n",
            "Epoch   6:  1500/ 2700 batches: accuracy    0.617\n",
            "Epoch   6:  2000/ 2700 batches: accuracy    0.616\n",
            "Epoch   6:  2500/ 2700 batches: accuracy    0.612\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   6: Time: 22.67, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n",
            "Epoch   7:   500/ 2700 batches: accuracy    0.617\n",
            "Epoch   7:  1000/ 2700 batches: accuracy    0.612\n",
            "Epoch   7:  1500/ 2700 batches: accuracy    0.616\n",
            "Epoch   7:  2000/ 2700 batches: accuracy    0.614\n",
            "Epoch   7:  2500/ 2700 batches: accuracy    0.614\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   7: Time: 22.79, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n",
            "Epoch   8:   500/ 2700 batches: accuracy    0.616\n",
            "Epoch   8:  1000/ 2700 batches: accuracy    0.615\n",
            "Epoch   8:  1500/ 2700 batches: accuracy    0.615\n",
            "Epoch   8:  2000/ 2700 batches: accuracy    0.615\n",
            "Epoch   8:  2500/ 2700 batches: accuracy    0.615\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   8: Time: 21.76, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n",
            "Epoch   9:   500/ 2700 batches: accuracy    0.614\n",
            "Epoch   9:  1000/ 2700 batches: accuracy    0.614\n",
            "Epoch   9:  1500/ 2700 batches: accuracy    0.617\n",
            "Epoch   9:  2000/ 2700 batches: accuracy    0.616\n",
            "Epoch   9:  2500/ 2700 batches: accuracy    0.614\n",
            "-----------------------------------------------------------\n",
            "End of Epoch   9: Time: 22.78, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n",
            "Epoch  10:   500/ 2700 batches: accuracy    0.613\n",
            "Epoch  10:  1000/ 2700 batches: accuracy    0.617\n",
            "Epoch  10:  1500/ 2700 batches: accuracy    0.615\n",
            "Epoch  10:  2000/ 2700 batches: accuracy    0.614\n",
            "Epoch  10:  2500/ 2700 batches: accuracy    0.617\n",
            "-----------------------------------------------------------\n",
            "End of Epoch  10: Time: 23.04, Valid Accuracy:    0.597\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(dlTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnC__MwvhaC_",
        "outputId": "da984621-c4f1-4f51-b314-5befad7a17f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5005470174524616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for predicting new input\n",
        "def predict(text, pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        print(output)\n",
        "        return torch.abs(output).argmax(1).item()"
      ],
      "metadata": {
        "id": "WyLmXgBFwKKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup to test MBTI output for strings\n",
        "s = 'I am an INTJ'\n",
        "label_map = {'I': 0, 'E': 1}\n",
        "mbti_map = {0: 'I', 1: 'E'}\n",
        "model = model.to('cpu')\n",
        "print(\"post: %s; \\nType: %s\" % (s, mbti_map[predict(s, text_pipe)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOYVBDKqvQL9",
        "outputId": "327a3201-855c-4805-a31b-e88d85ddaab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4082, -0.8929]])\n",
            "post: im post malone i love cleveland; \n",
            "Type: E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"SAVETHISthinkfeel\")"
      ],
      "metadata": {
        "id": "K5xlZbkNLaYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Confusion Matrix creation\n",
        "# Iterates through entire dataloader, keeping track of true positives,\n",
        "#   false positives, false negatives, and true positives\n",
        "def evalList(dl):\n",
        "  model.eval()\n",
        "  tp, fp, fn, tn = 0, 0, 0, 0\n",
        "  #\n",
        "  #   TP    FP\n",
        "  #\n",
        "  #   FN    TN\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dl):\n",
        "      predLabel = model(text, offsets)\n",
        "\n",
        "      for idx, target in enumerate(predLabel.argmax(1)):\n",
        "        trueLabel = label[idx].item()\n",
        "        guess = target.item()\n",
        "\n",
        "        if trueLabel == 1:\n",
        "          if guess == 1:\n",
        "            tp += 1\n",
        "          else:\n",
        "            fn += 1\n",
        "        else: #true label is 0\n",
        "          if guess == 1:\n",
        "            fp += 1\n",
        "          else:\n",
        "            tn += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #print(predLabel)\n",
        "      #print(predLabel.argmax(1))\n",
        "      #print(label)\n",
        "\n",
        "      #for idx, target in enumerate(predLabel.argmax(1)):\n",
        "      #  print(target.item())\n",
        "      #  print(label[idx].item())\n",
        "      #  break\n",
        "      #break\n",
        "  return (tp, fp, fn, tn)"
      ],
      "metadata": {
        "id": "mKK0I3imMOhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v29nGu40fEl",
        "outputId": "f7b420a7-62db-413f-d74d-51ec2e501d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): EmbeddingBag(160930, 64, mode='mean')\n",
              "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(tp, fp, fn, tn) = evalList(dlTest)\n",
        "#(clTe, evTe) = evalList(testset)\n",
        "#(clV, evV) = evalList(valset)"
      ],
      "metadata": {
        "id": "cx7kTx4sNsW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extrovert / Extrovert: %d \\tExtrovert / Introvert: %d\\n Introvert / Extrovert: %d \\tIntrovert / Introvert: %d\" % (tp, fp, fn, tn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKPaNDvnjKX7",
        "outputId": "3638d7f0-fc78-4c18-c1dc-e81d62806bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrovert / Extrovert: 7128 \tExtrovert / Introvert: 5369\n",
            " Introvert / Extrovert: 2458 \tIntrovert / Introvert: 4240\n"
          ]
        }
      ]
    }
  ]
}